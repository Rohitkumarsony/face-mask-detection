{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb514a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Download dataset (cached by kagglehub)\n",
    "cache_path = kagglehub.dataset_download(\"omkargurav/face-mask-dataset\")\n",
    "print(\"Downloaded to cache:\", cache_path)\n",
    "\n",
    "# Your LOCAL project directory\n",
    "target_dir = os.path.join(os.getcwd(), \"face_mask_dataset\")\n",
    "\n",
    "# Create directory if not exists\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Copy dataset from cache to project folder\n",
    "shutil.copytree(cache_path, target_dir, dirs_exist_ok=True)\n",
    "\n",
    "print(\"Dataset copied to:\", target_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301980f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!ls face_mask_dataset/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6714e2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47bc537",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "DATA_DIR = \"face_mask_dataset/data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff4a81e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,   # 80% train, 20% val\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_data = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b56ea10",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(\n",
    "    input_shape=(224,224,3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "base_model.trainable = False  # IMPORTANT for fast training\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e750a2a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d0ba6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d73d7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"face_mask_detection_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05dd3e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Face Mask Detection - URL Input\n",
    "# ================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# ---- CONFIG ----\n",
    "IMG_SIZE = (224, 224)   # same size used during training\n",
    "\n",
    "# ---- USER INPUT ----\n",
    "image_url = input(\"ðŸ‘‰ Paste image URL here: \")\n",
    "\n",
    "# ---- LOAD IMAGE FROM URL ----\n",
    "response = requests.get(image_url)\n",
    "img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "img = img.resize(IMG_SIZE)\n",
    "\n",
    "# ---- PREPROCESS ----\n",
    "img_array = img_to_array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# ---- PREDICT ----\n",
    "pred = model.predict(img_array)[0][0]\n",
    "\n",
    "if pred < 0.5:\n",
    "    label = \"With Mask ðŸ˜·\"\n",
    "    confidence = (1 - pred) * 100\n",
    "else:\n",
    "    label = \"Without Mask âŒ\"\n",
    "    confidence = pred * 100\n",
    "\n",
    "# ---- DISPLAY RESULT ----\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"{label} | Confidence: {confidence:.2f}%\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
